<!DOCTYPE html>
<!-- saved from url=(0031)https://duseongchang.github.io/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Du-Seong Chang</title>
  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Du-Seong Chang</title>
<meta name="generator" content="Jekyll v3.10.0">
<meta property="og:title" content="Du-Seong Chang">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Du-Seong Chang">
<meta property="og:type" content="website">
<meta name="twitter:card" content="summary">
<meta property="twitter:title" content="Du-Seong Chang">
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebSite","headline":"Du-Seong Chang","name":"Du-Seong Chang","url":"/"}</script>
<!-- End Jekyll SEO tag -->


  <link rel="icon" type="image/png" href="https://duseongchang.github.io/assets/img/icon.webp">
  <link rel="shortcut icon" type="image/png" href="https://duseongchang.github.io/assets/img/icon.webp">
  <link rel="stylesheet" href="./Du-Seong Chang_files/style.css">
  <link href="./Du-Seong Chang_files/css" rel="stylesheet">
</head>

<body>
  <div id="sidebar">
    <ul class="toc-box"><li id="toc-id-
            
              
            
            Professional Experiences
          " class=""><a class="content-link">
            
              
            
            Professional Experiences
          </a></li><li id="toc-id-
            
              
            
            Research Interest &amp; Projects
          " class=""><a class="content-link">
            
              
            
            Research Interest &amp; Projects
          </a></li><li id="toc-id-
            
              
            
            Publications
          " class=""><a class="content-link">
            
              
            
            Publications
          </a></li><li id="toc-id-
            
              
            
            We are hiring...
          "><a class="content-link">
            
              
            
            We are hiring...
          </a></li><li id="toc-id-
            
              
            
            Members
          "><a class="content-link">
            
              
            
            Members
          </a></li></ul>
  </div>
  <div id="about">
    <div class="profile-zone">
      <img class="profile-img" src="./Du-Seong Chang_files/PF-dschang4.jpg" alt="My Photo">
      <ul class="personal-info">
        
        
          <li><a aria-label="My Email" href="mailto:duseong.chang AT gmail.com">
            <img src="./Du-Seong Chang_files/envelope.svg" alt="My Email">
            <div><span>duseong.chang AT gmail.com</span></div>
          </a></li>
        
        
          <li><a aria-label="My LinkedIn" href="https://www.linkedin.com/in/duseongchang">
            <img src="./Du-Seong Chang_files/linkedin.svg" alt="My LinkedIn">
            <div><span>@duseongchang</span></div>
          </a></li>
        
        
        
        
        
        
        
          <li><a aria-label="My Blog" href="https://duseongchang.github.io/">
            <img src="./Du-Seong Chang_files/house.svg" alt="My Blog">
            <div><span>https://duseongchang.github.io/</span></div>
          </a></li>
        
        
        <li><a aria-label="My Address" href="https://www.google.com/maps/search/TE512%20Sogang%20Univ.%20Seoul,%20Korea">
          <img src="./Du-Seong Chang_files/location-dot.svg" alt="My Address">
          <div><span>TE512 Sogang Univ. Seoul, Korea</span></div>
        </a></li>
        
        
          <li><a aria-label="My Google" href="https://scholar.google.co.kr/citations?user=y1HTwWAAAAAJ&amp;sortby=pubdate">
            <img src="./Du-Seong Chang_files/graduation-cap.svg" alt="My Google Scholor">
            <div><span>https://scholar.google.co.kr/citations?user=y1HTwWAAAAAJ&amp;sortby=pubdate</span></div>
          </a></li>
        
      </ul>
    </div>
    <div class="name-zone">
      <h1>Du-Seong Chang</h1>
      <h2>Associate Professor, Dept. of Artificial Intelligence, Sogang Univ.</h2>
    </div>
  </div>
  <div id="contents">
    <ul>
      
        <li class="subject appear" id="Professional Experiences">
          <h2 class="subject-name">
            <div>
              <img class="subject-icon" src="./Du-Seong Chang_files/briefcase.svg" alt="Professional Experiences">
            </div>
            Professional Experiences
          </h2>
          <ul>
              
              <li class="item appear">
                  <div class="content-header">
                    <p>AI Transformation in customer service and product utilizing a Large Language Model</p>

                    
                  </div>
                  
                    
                  
                    
                      
                        <p>Senior Vice President, Tech Lead of KT AI Bussiness Unit</p>

                      
                    
                  
                    
                      
                        <ul>
                          
                          <li class="subitem">
                            <p>Cloud-based AI Contact Center, Commerce, Advertising, and AI Assistant over Intelligent Network</p>

                          </li>
                          
                        </ul>
                      
                    
                  
              </li>
              
              <li class="item appear">
                  <div class="content-header">
                    <p>R&amp;D Head of Large AI, NLP, Conversational AI, Big Data, and Recommandation</p>

                    
                  </div>
                  
                    
                  
                    
                      
                        <p>Vice President, KT Converged Research Laboratories</p>

                      
                    
                  
                    
                      
                        <ul>
                          
                          <li class="subitem">
                            <p>Project Head of Large AI <strong>Mi:dm</strong>, AI Assistant <strong>Giga-Genie</strong>, <strong>KT AI Contact Center</strong></p>

                          </li>
                          
                          <li class="subitem">
                            <p>Project Leader of Spoken Dialogue System, Sementaic Search, Personalized Curation of IPTV <strong>Ginie TV</strong></p>

                          </li>
                          
                        </ul>
                      
                    
                  
              </li>
              
              <li class="item appear">
                  <div class="content-header">
                    <p>Question Answering, Knowledge Mining, Reasoning, and Fundamental NLP Core Technologies</p>

                    
                  </div>
                  
                    
                  
                    
                      
                        <p>PhD in Computer Science, KAIST &amp; Semantic Web Research Center</p>

                      
                    
                  
                    
                      
                        <ul>
                          
                          <li class="subitem">
                            <p>Causality Mining, Knowledge based Question Answering, Semantic Web <strong>CoreNet</strong></p>

                          </li>
                          
                        </ul>
                      
                    
                  
              </li>
              
              <li class="item appear">
                  <div class="content-header">
                    <p>Statistical NLP &amp; Spoken Language Technologies</p>

                    
                  </div>
                  
                    
                  
                    
                      
                        <p>MA in Computer Science, KAIST &amp; Research Scientist in Korea Telecom</p>

                      
                    
                  
                    
                      
                        <ul>
                          
                          <li class="subitem">
                            <p>Korean Morphological &amp; Syntactic Aanlysis, POS Tagger <strong>KTS</strong></p>

                          </li>
                          
                          <li class="subitem">
                            <p>Spoken Language Modeling, Text-to-Speech System <strong>Hansori</strong>, Speech Translation System</p>

                          </li>
                          
                        </ul>
                      
                    
                  
              </li>
              
          </ul>
        </li>
      
        <li class="subject appear" id="Research Interest &amp; Projects">
          <h2 class="subject-name">
            <div>
              <img class="subject-icon" src="./Du-Seong Chang_files/clipboard-list.svg" alt="Research Interest &amp; Projects">
            </div>
            Research Interest &amp; Projects
          </h2>
          <ul>
              
              <li class="item appear">
                  <div class="content-header">
                    <p>Enhanced Reasoning in Large AI / eXplainable AI</p>

                    
                  </div>
                  
                    
                  
                    
                      
                        <p>AI 추론 결과는 사실에 근거하고 그 추론 과정은 설명가능 하여야 합니다. Large AI가 문제의 해결을 위한 연쇄적인 추론 단계를 배우는 것은 실제 AI의 추론 성능을 향상시키며, 응답 결과가 어떠한 근거에서 도출되었는지를 설명할 수 있는 근거가 됩니다. Large AI가 추론 과정에서 타깃 영역별 지식정보, 신뢰도, 설명가능성을 이용하여 최적의 경로를 선택한다면, 전문가 수준의 높은 추론 능력을 확보할 수 있습니다. 이러한 여러 자원을 이용한 향상된 AI 추론 방법론을 개발하여 한국어 Large AI의 성능을 높이고, 전문가 영역에서 의사결정을 지원할 수 있는 수준의 추론능력을 얻을 수 있도록 기술을 확대 개발하고 있습니다.</p>

                      
                    
                  
                    
                      
                        <ul>
                          
                          <li class="subitem">
                            <p><strong>“대화 기반 설명가능성을 멀티모달로 제공하는 인공지능 기술 개발” 국책과제 (2022 - 2026)</strong></p>

                          </li>
                          
                          <li class="subitem">
                            <p>“설명가능한 전문가 의사결정 지원기술 개발” 국책과제 (공동연구 책임자, 2022 - 2024)</p>

                          </li>
                          
                          <li class="subitem">
                            <p>NeurIPS2024, “How Do Large Language Models Acquire Factual Knowledge During Pretraining?”</p>

                          </li>
                          
                        </ul>
                      
                    
                  
              </li>
              
              <li class="item appear">
                  <div class="content-header">
                    <p>AI Alignment / Responsible AI</p>

                    
                  </div>
                  
                    
                  
                    
                      
                        <p>바람직한 AI 모델은 인간의 의지와 정렬된 행동을 하여 사용성이 높고, 사회/윤리성을 가진 행동을 하며, 사실에 기반한 공정한 응답을 할 수 있어야 합니다. AI를 이러한 방향으로 학습하기 위한 AI Alignment기술을 개발하고 한국어 Large AI모델에 선도 적용하고 있습니다. 기술 확대를 위해 인지/사회/언어학계 및 여러 초거대AI 사업체들과 함께 컨소시엄을 이루어 협의하고 요소 기술을 개발하고 있으며, AI평가체계를 마련하고 공개하여 국가 기술 발전에 기여하고 있습니다.</p>

                      
                    
                  
                    
                      
                        <ul>
                          
                          <li class="subitem">
                            <p><strong>“생성형 AI의 사회/윤리성 향상 연구개발” 국책과제 (공동연구 책임자, 3년, Mar. 2024 – 2026)</strong></p>

                          </li>
                          
                          <li class="subitem">
                            <p>IITP/NIA “초거대AI 윤리/유용성 평가 데이터 구축” 국책과제 (자문위원, Jul. 2023 – Jan. 2024)</p>

                          </li>
                          
                          <li class="subitem">
                            <p>ACL2025, “Evaluating Visual and Cultural Interpretation: The K-Viscuit Benchmark with Human-VLM Collaboration”</p>

                          </li>
                          
                        </ul>
                      
                    
                  
              </li>
              
              <li class="item appear">
                  <div class="content-header">
                    <p>Multi Agentic AI / Large AI Transformation</p>

                    
                  </div>
                  
                    
                  
                    
                      
                        <p>생성형 AI에 기반한 에이전트 기술은 단순한 하나의 단일 모델에서 벗어나 여러 단계의 수행 계획을 스스로 수립하고 실생활의 여러 도구를 사용하여 확보된 정보와 주변 에이전트간의 협력에 기반하여 결과물을 도출하고, 이에 기반한 실세계의 행동을 수행하는 멀티 에이전트 기술로 진화되고 있습니다. 에이전트에 기반한 서비스 모델링 기술은 기존의 금융, 공공, 행정, 법률 등 다양한 영역에서 기존 서비스를 혁신하고 있으며, 화자인식, 음성메모, 상담분류/요약, 상담대화, 추천, 질의응답 등의 결합으로 AI기반 Contact Center, 통화비서, 문자광고/커머스 등과 같은 새로운 사업 형상이 등장하고 있습니다. Large AI Transformation의 영역은 교육, 농업, 해양관제 등 다양한 영역으로 확대 예정입니다.</p>

                      
                    
                  
                    
                      
                        <ul>
                          
                          <li class="subitem">
                            <p><strong>“멀티 에이전트에 기반한 농작물 멀티모달 질의응답 시스템 개발” (연구책임자, 2025 - Present)</strong></p>

                          </li>
                          
                          <li class="subitem">
                            <p>Large AI 기반의 AI전화 Assistant(통화비서), AI문자광고 카피라이터, ACen Cloud</p>

                          </li>
                          
                          <li class="subitem">
                            <p>KT AICC Project, Text Analytics(2018), 상담Assist(2020), 상담보이스봇(2021)</p>

                          </li>
                          
                          <li class="subitem">
                            <p>국립국어원 AI경진대회 ”AI말평” 자문 및 심사위원(2023 - 2025)</p>

                          </li>
                          
                          <li class="subitem">
                            <p>NIA AI Hub “데이터댐 사업” 데이터 구축/활용 자문위원(2021, 2022), NIA AI경진대회 심사위원(2022, 2023)</p>

                          </li>
                          
                        </ul>
                      
                    
                  
              </li>
              
              <li class="item appear">
                  <div class="content-header">
                    <p>Large AI Enabling Core Technology</p>

                    
                  </div>
                  
                    
                  
                    
                      
                        <p>10여 개 산/학/연 공동개발 프로젝트를 통해 효율적인 Large AI 학습/추론 알고리즘, 경량화 학습, 데이터 증강기술, 한국어 명령어 학습, 강화학습 알고리즘 등의 한국형 Large AI기술을 선도 개발하였으며, 기가지니, AICC, 지니TV 등의 사업에 적용하고, 바우처 사업과 AI모델 공개로 국가 Large AI Eco 확산에도 기여하고 있습니다.</p>

                      
                    
                  
                    
                      
                        <ul>
                          
                          <li class="subitem">
                            <p>한국형 초거대AI기술 선도연구 “초거대AI 믿:음 개발” 연구책임자, (2019 - 2024)</p>

                          </li>
                          
                          <li class="subitem">
                            <p>Large AI 기반 AX Projects, 기가지니(2021), AICC(2022), 지니TV 큐레이션(2023) 연구책임자</p>

                          </li>
                          
                          <li class="subitem">
                            <p>AAAI2025, RILQ: Rank-Insensitive LoRA-based Quantization Error Compensation for Boosting 2-bit Large Language Model Accuracy</p>

                          </li>
                          
                          <li class="subitem">
                            <p>EMNLP2024, Towards Fast Multilingual LLM Inference: Speculative Decoding and Specialized Drafters</p>

                          </li>
                          
                          <li class="subitem">
                            <p>ACL2024, Improving Conversational Abilities of Quantized LLMs via Direct Preference Alignment</p>

                          </li>
                          
                          <li class="subitem">
                            <p>ASPLOS2024, Exegpt: Constraint-aware resource scheduling for llm inference</p>

                          </li>
                          
                          <li class="subitem">
                            <p>NeurIPS2023, Token-scaled logit distillation for ternary weight generative language models</p>

                          </li>
                          
                          <li class="subitem">
                            <p>EMNLP2023, NASH: A Simple Unified Framework of Structured Pruning for Accelerating Encoder-Decoder LMs</p>

                          </li>
                          
                          <li class="subitem">
                            <p>정보과학회지, Large AI to Everywhere, 초거대 AI 믿:음</p>

                          </li>
                          
                        </ul>
                      
                    
                  
              </li>
              
              <li class="item appear">
                  <div class="content-header">
                    <p>Natural Language Processing &amp; Conversational AI</p>

                    
                  </div>
                  
                    
                  
                    
                      
                        <p>한국어 대화/질의응답 기술을 개발하고, 한국어 음성인식/합성기술과 결합하여 한국어 음성대화 기술을 개발합니다. 생성형AI에 기반한 에이전트의 Plan수립, 대화 의도해석 및 멀티턴 추론 기술을 연구합니다. 형태소분석, 품사태거, 구문분석, 의미분석, 개체명태깅, 담화분류 등의 한국어 NLP 요소기술의 원리를 파악하고, 생성형AI에 기반한 정보추출, 기계독해, 질의응답, 문서요약, 오류교정, 의도기반 검색 등 응용기술을 개발합니다.</p>

                      
                    
                  
                    
                      
                        <ul>
                          
                          <li class="subitem">
                            <p>국내 최초의 AI TV 기가지니 개발 및 출시 (2017, 대화비서 Agent 연구책임자)</p>

                          </li>
                          
                          <li class="subitem">
                            <p>“ExoBrain: 빅데이터 기반 자가학습형 지식베이스/추론기술” (공동연구책임자, 10년, 274억, 2014 – 2023)</p>

                          </li>
                          
                          <li class="subitem">
                            <p>“다중영역 대화형 개인비서 SW 원천기술” 국책과제 (공동연구 책임자, 3년, 총액 75억, Mar. 2012 – Feb. 2015)</p>

                          </li>
                          
                          <li class="subitem">
                            <p>“음성대화형 홈네트워크/IPTV 제어 기술 개발” (대화시스템 연구책임자, Mar. 2005 – Apr. 2015)</p>

                          </li>
                          
                          <li class="subitem">
                            <p>ACL2024, “Guidance-Based Prompt Data Augmentation in Specialized Domains for Named Entity Recognition”</p>

                          </li>
                          
                          <li class="subitem">
                            <p>Coling2024, “PSYDIAL: Personality-based Synthetic Dialogue Generation using Large Language Models”</p>

                          </li>
                          
                          <li class="subitem">
                            <p>IUI2023, “Interactive User Interface for Dialogue Summarization”</p>

                          </li>
                          
                          <li class="subitem">
                            <p>정보과학회지, “지능형 대화비서: GiGA Genie Assistant”</p>

                          </li>
                          
                        </ul>
                      
                    
                  
              </li>
              
              <li class="item appear">
                  <div class="content-header">
                    <p>Personalized Recommandation &amp; Curation</p>

                    
                  </div>
                  
                    
                  
                    
                      
                        <p>대규모 상용 로그를 실시간 분석하는 딥러닝 개인화 추천 기술 개발, 국내 최초 개인화 큐레이션 사업화</p>

                      
                    
                  
                    
                      
                        <ul>
                          
                          <li class="subitem">
                            <p>국내 최대 미디어 셋탑박스인 지니TV에 시맨틱검색 및 개인화된 편성(큐레이션) 사업화 (2015)</p>

                          </li>
                          
                          <li class="subitem">
                            <p>한국콘텐츠학회 논문지, “감성 정보 기반 맞춤형 미디어콘텐츠 큐레이션 시스템 개발”</p>

                          </li>
                          
                        </ul>
                      
                    
                  
              </li>
              
              <li class="item appear">
                  <div class="content-header">
                    <p>Multimodal / Vision Language Model</p>

                    
                  </div>
                  
                    
                  
                    
                      
                        <p>한국어 VLM 데이터 구축 및 학습/추론 모델 구조화로 한국어 Large Multimodal Model 선도 개발</p>

                      
                    
                  
                    
                      
                        <ul>
                          
                          <li class="subitem">
                            <p>Large Vision Language Model 개발 (연구책임자, 2021 – 2024)</p>

                          </li>
                          
                          <li class="subitem">
                            <p>ECCV2024, “BI-MDRG: Bridging Image History in Multimodal Dialogue Response Generation”</p>

                          </li>
                          
                          <li class="subitem">
                            <p>ACL2024 Findings, “Translation Deserves Better: Analyzing Translation Artifacts in Cross-lingual Visual QA”</p>

                          </li>
                          
                          <li class="subitem">
                            <p>AAAI2024, “Structure-Aware Multimodal Sequential Learning for Visual Dialog”</p>

                          </li>
                          
                        </ul>
                      
                    
                  
              </li>
              
          </ul>
        </li>
      
        <li class="subject appear" id="Publications">
          <h2 class="subject-name">
            <div>
              <img class="subject-icon" src="./Du-Seong Chang_files/flask.svg" alt="Publications">
            </div>
            Publications
          </h2>
          <ul>
              
              <li class="item appear">
                  <div class="content-header">
                    <p>International Journal &amp; Conference</p>

                    
                  </div>
                  
                    
                  
                    
                      
                        <ul>
                          
                          <li class="subitem">
                            <p>GY Baek, CH Park, J Kim, YJ Heo, DS Chang, J Choo, “Evaluating Visual and Cultural Interpretation: The K-Viscuit Benchmark with Human-VLM Collaboration”, ACL2025</p>

                          </li>
                          
                          <li class="subitem">
                            <p>G Lee, J Lee, S Hong, M Kim, E Ahn, DS Chang, J Choi, “RILQ: Rank-Insensitive LoRA-based Quantization Error Compensation for Boosting 2-bit Large Language Model Accuracy”, AAAI2025</p>

                          </li>
                          
                          <li class="subitem">
                            <p>HS Yoon, E Yoon, JTJ Tee, K Zhang, YJ Heo, DS Chang, CD Yoo, “BI-MDRG: Bridging Image History in Multimodal Dialogue Response Generation”, ECCV2024</p>

                          </li>
                          
                          <li class="subitem">
                            <p>E Yi, T Kim, H Jeung, DS Chang, SY Yun, “Towards Fast Multilingual LLM Inference: Speculative Decoding and Specialized Drafters”, EMNLP2024</p>

                          </li>
                          
                          <li class="subitem">
                            <p>H Chang, J Park, S Ye, S Yang, Y Seo, DS Chang, M Seo, “How Do Large Language Models Acquire Factual Knowledge During Pretraining?”, NeurIPS2024</p>

                          </li>
                          
                          <li class="subitem">
                            <p>Hyeonseok Kang, Hyein Seo, Jeesu Jung, Sangkeun Jung, Du-Seong Chang, Riwoo Chung, “Guidance-Based Prompt Data Augmentation in Specialized Domains for Named Entity Recognition”, ACL2024</p>

                          </li>
                          
                          <li class="subitem">
                            <p>J Lee, S Park, S Hong, M Kim, DS Chang, J Choi, “Improving Conversational Abilities of Quantized Large Language Models via Direct Preference Alignment”, ACL2024</p>

                          </li>
                          
                          <li class="subitem">
                            <p>CH Park, K Lee, H Lim, J Kim, J Park, YJ Heo, DS Chang, J Choo, “Translation Deserves Better: Analyzing Translation Artifacts in Cross-lingual Visual Question Answering”, ACL2024 Findings</p>

                          </li>
                          
                          <li class="subitem">
                            <p>JW Kim, JE Han, JS Koh, HT Seo, DS Chang, “Enhancing Psychotherapy Counseling: A Data Augmentation Pipeline Leveraging LLMs for Counseling Conversations”, IJCAI2024 AI4Research workshop</p>

                          </li>
                          
                          <li class="subitem">
                            <p>Y Seo, Y Heo, JS Koh, DS Chang, “Efficient and Accurate Memorable Conversation Model using DPO based on sLLM”, IJCAI2024 LKM workshop</p>

                          </li>
                          
                          <li class="subitem">
                            <p>J Ahn, J Park, MJ Kim, KH Kim, SY Sohn, YJ Lee, DS Chang, YJ Heo, ES Kim, “Solution for SMART-101 Challenge of CVPR Multi-modal Algorithmic Reasoning Task 2024”, CVPR2024 workshop</p>

                          </li>
                          
                          <li class="subitem">
                            <p>H Oh, K Kim, J Kim, S Kim, J Lee, D Chang, J Seo, “Exegpt: Constraint-aware resource scheduling for llm inference”, Proceedings of the 29th ACM International Conference on ASPLOS, Volume 2, 2024</p>

                          </li>
                          
                          <li class="subitem">
                            <p>JE Han, JS Koh, HT Seo, DS Chang, KA Sohn, “PSYDIAL: Personality-based Synthetic Dialogue Generation using Large Language Models”, LREC-Coling2024</p>

                          </li>
                          
                          <li class="subitem">
                            <p>YJ Kim, MJ Kim, K An, J Ahn, J Kim, YJ Heo, DS Chang, ES Kim, “Structure-Aware Multimodal Sequential Learning for Visual Dialog”, Proceedings of the AAAI Conference on Artificial Intelligence 38 (12), 2024</p>

                          </li>
                          
                          <li class="subitem">
                            <p>M Kim, S Lee, J Lee, S Hong, DS Chang, W Sung, J Choi, “Token-scaled logit distillation for ternary weight generative language models”, Advances in Neural Information Processing Systems 36 (NuerIPS2023)</p>

                          </li>
                          
                          <li class="subitem">
                            <p>J Ko, S Park, Y Kim, S Ahn, DS Chang, E Ahn, SY Yun, “NASH: A Simple Unified Framework of Structured Pruning for Accelerating Encoder-Decoder Language Models”, EMNLP2023</p>

                          </li>
                          
                          <li class="subitem">
                            <p>J Jung, H Seo, S Jung, R Chung, H Ryu, DS Chang, “Interactive User Interface for Dialogue Summarization”, Proceedings of the 28th International Conference on Intelligent User Interfaces, 2023 (IUI2023)</p>

                          </li>
                          
                          <li class="subitem">
                            <p>J Ko, S Park, M Jeong, S Hong, E Ahn, DS Chang, SY Yun, “Revisiting intermediate layer distillation for compressing language models: An overfitting perspective”, EACL2023 Findings</p>

                          </li>
                          
                          <li class="subitem">
                            <p>M Kim, S Lee, S Hong, DS Chang, J Choi, “Understanding and improving knowledge distillation for quantization-aware training of large transformer encoders”, EMNLP2022</p>

                          </li>
                          
                          <li class="subitem">
                            <p>HS Sim, KE Kim, JH Kim, DS Chang, MW Koo, “Symbolic Heuristic Search Value Iteration for Factored POMDPs.”, Proceedings of the AAAI Conference on Artificial Intelligence, 1088-1093, 2008 (AAAI08)</p>

                          </li>
                          
                          <li class="subitem">
                            <p>DS Chang, KS Choi, “Incremental cue phrase learning and bootstrapping method for causality extraction using cue phrase and word pair probabilities”, Information processing &amp; management 42 (3), 662-678, 2006</p>

                          </li>
                          
                          <li class="subitem">
                            <p>DS Chang, KS Choi, “Causal relation extraction using cue phrase and lexical pair probabilities”, International Conference on Natural Language Processing, 61-70, 2004 (IJCNLP04)</p>

                          </li>
                          
                          <li class="subitem">
                            <p>KS Choi, DS Chang, “A Computational Causality for Explanatory Language Understanding”, 亚太地区国际脑研究研讨会论文集, 2004</p>

                          </li>
                          
                          <li class="subitem">
                            <p>JH Oh, KS Lee, DS Chang, CW Seo, KS Choi, “TREC-10 Experiments at KAIST: Batch Filtering and Question Answering”, TREC-10 conference, 2001</p>

                          </li>
                          
                          <li class="subitem">
                            <p>DS Chang, YK Hong, JI Kim, JY Kim, “Hansori97: The Unlimited Korean Text-To-Speech System”, Proceedings of 4th conference on Natural Language Processing Pacific-Rim Symposium, 1997</p>

                          </li>
                          
                          <li class="subitem">
                            <p>W Kim, DS Chang, JI Kim, MW Koo, “A Multi-lingual Speech Translation System for Hotel Reservation”, Proceedings of the Korea-China Joint Symposium on Oriental Language Computing, 1996</p>

                          </li>
                          
                          <li class="subitem">
                            <p>MW Koo, IH Sohn, W Kim, DS Chang, “KT-STS: a speech translation system for hotel reservation and a continuous speech recognition system for speech translation”, Eurospeech95, 1227-1230, 1995</p>

                          </li>
                          
                        </ul>
                      
                    
                  
              </li>
              
              <li class="item">
                  <div class="content-header">
                    <p>Domestic Journal</p>

                    
                  </div>
                  
                    
                  
                    
                      
                        <ul>
                          
                          <li class="subitem">
                            <p>서민택, 임준호, 김태형, 류휘정, 장두성, 나승훈, “Improving Retrieval Models through Reinforcement Learning with Feedback”, 정보과학회논문지 50 (10), 900-907, 2024</p>

                          </li>
                          
                          <li class="subitem">
                            <p>장두성, 류휘정, 원세연, 안의재, “Large AI to Everywhere, 초거대 AI 믿:음”, 정보과학회지 41 (11), 48-57, 2023</p>

                          </li>
                          
                          <li class="subitem">
                            <p>이건희, 나승훈, 임준호, 김태형, 장두성, “PrefixLM 에 기반한 한국어 텍스트 요약”, 정보과학회논문지 49 (6), 475-487, 2022</p>

                          </li>
                          
                          <li class="subitem">
                            <p>최윤수, 이혜우, 김태형, 이영훈, 나승훈, 장두성, “RoBERTa 를 이용한 한국어 기계독해”, 정보과학회 컴퓨팅의 실제 논문지 27 (4), 198-203, 2021</p>

                          </li>
                          
                          <li class="subitem">
                            <p>장두성, 성주원, 임지희, “지능형 대화비서: GiGA Genie Assistant”, 정보과학회지, 2017</p>

                          </li>
                          
                          <li class="subitem">
                            <p>임지희, 최호섭, 옥철영, 장두성, “감성 정보 기반 맞춤형 미디어콘텐츠 큐레이션 시스템 개발”, 한국콘텐츠학회논문지 16 (12), 181-191, 2016</p>

                          </li>
                          
                          <li class="subitem">
                            <p>김종환, 장두성, 김학수, “복합 자질 정보를 이용한 통계적 한국어 채팅 문장 생성”, 인지과학 20 (4), 421-437, 2009</p>

                          </li>
                          
                          <li class="subitem">
                            <p>강승식, 장두성, “SMS 변형된 문자열의 자동 오류 교정 시스템”, 정보과학회논문지: 소프트웨어 및 응용 35 (6), 386-391, 2008</p>

                          </li>
                          
                          <li class="subitem">
                            <p>이신목, 장두성, 신지애, “자질별 관계 패턴의 다변화를 통한 온톨로지 확장”, 정보처리학회논문지 B, 제 15-B 권, 2008</p>

                          </li>
                          
                          <li class="subitem">
                            <p>오종훈, 장두성, 김재호, 최기선, “인간의 지식처리 모델링을 위한 전문분야 지식베이스 원형 구축 및 활용 연구”, 한국뇌학회지, Vol.3, No.1, pp.126-127, 2001</p>

                          </li>
                          
                          <li class="subitem">
                            <p>장두성, 구명완, “의존문법을 후향 언어모델로 사용하는 한국어 연속음성 인식시스템”, 정보과학회논문지 (B) 24 (4), 443-449, 1997</p>

                          </li>
                          
                          <li class="subitem">
                            <p>구명완, 김재인, 박상규, 김우성, 장두성, 홍영국, 장경애, 김응인, 강용범, “호텔예약을 위한 음성번역시스템”, 한국음향학회지 15 (4), 24-31, 1996</p>

                          </li>
                          
                        </ul>
                      
                    
                  
              </li>
              
              <li class="item">
                  <div class="content-header">
                    <p>Full publication list</p>

                    
                  </div>
                  
                    
                  
                    
                      
                        <ul>
                          
                          <li class="subitem">
                            <p><a href="https://scholar.google.co.kr/citations?user=y1HTwWAAAAAJ&amp;sortby=pubdate">Google Scholar</a></p>

                          </li>
                          
                        </ul>
                      
                    
                  
              </li>
              
          </ul>
        </li>
      
        <li class="subject" id="We are hiring...">
          <h2 class="subject-name">
            <div>
              <img class="subject-icon" src="./Du-Seong Chang_files/trophy.svg" alt="We are hiring...">
            </div>
            We are hiring...
          </h2>
          <ul>
              
              <li class="item">
                  <div class="content-header">
                    <p>거인의 어깨에서 세상을 더 멀리 바라보고 싶은 팀원을 찾습니다. 학부인턴 및 석박사과정 지원자를 모집합니다.</p>

                    
                  </div>
                  
                    
                  
                    
                      
                        <ul>
                          
                          <li class="subitem">
                            <p>Mail to <a href="https://duseongchang.github.io/">Du-Seong Chang</a></p>

                          </li>
                          
                        </ul>
                      
                    
                  
              </li>
              
          </ul>
        </li>
      
        <li class="subject" id="Members">
          <h2 class="subject-name">
            <div>
              <img class="subject-icon" src="./Du-Seong Chang_files/globe.svg" alt="Members">
            </div>
            Members
          </h2>
          <ul>
              
              <li class="item">
                  <div class="content-header">
                    <p>Natural Language Processing &amp; ISDS Lab</p>

                    
                  </div>
                  
                    
                  
                    
                      
                        <p>회사가 여러분에게 줄 수 있는 가장 큰 복지는 같은 방향을 보고 논의할 수 있는 동료의 존재입니다.</p>

                      
                    
                  
                    
                      
                        <ul>
                          
                          <li class="subitem">
                            <p><a href="https://isds.sogang.ac.kr/page/members">members</a></p>

                          </li>
                          
                        </ul>
                      
                    
                  
              </li>
              
          </ul>
        </li>
      
      </ul>
  </div>

<script src="./Du-Seong Chang_files/main.js"></script>

</body></html>